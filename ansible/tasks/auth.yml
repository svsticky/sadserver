---
# Contains a snapshot of the hostkeys of github.com, so these can be validated
# at runtime
- name: "install system-wide known hostkeys"
  template:
    src: "templates/etc/ssh/ssh_known_hosts"
    dest: "/etc/ssh/ssh_known_hosts"
    owner: "root"
    group: "root"
    mode: "0644"

- name: "set NOPASSWD for sudo group in staging"
  lineinfile:
    dest: "/etc/sudoers.d/ansible"
    line: "%sudo ALL=(ALL:ALL) NOPASSWD:ALL"
    state: "{% if 'staging' in group_names %}present{% else %}absent{% endif %}"
    create: true
    validate: "visudo -cf %s"

- name: "check if password of admin user is locked"
  shell: "passwd --status {{ item.name }} | awk '{print $2}'"
  register: "admin_passwords"
  with_items: "{{ users }}"
  when:
    # List is evaluated as logical AND
    - "'staging' not in group_names"
    - item.admin
    - item.state == "present"
    - item.name != "ansible"
  changed_when: false
  loop_control:
    label: "{{ item.name }}"
  check_mode: false

- name:
    "make new admin users choose a password at next login, in production"
  command: "passwd -de {{ item.item.name }}"
  with_items: "{{ admin_passwords.results }}"
  when:
    # List is evaluated as logical AND
    - "'staging' not in group_names"
    - item.stdout is defined
    - item.stdout == "L"
  loop_control:
    label:
      user: "{{ item.item.name }}"

- name: "ensure .ssh-directory is present at all users"
  file:
    path: "{{ item.0.home_prefix }}/{{ item.0.name }}/.ssh"
    state: "directory"
    owner: "{{ item.0.name }}"
    group: "{{ item.0.name }}"
    mode: "0755"
  when: item.0.state == 'present'
  with_subelements:
    - "{{ users }}"
    # "Keys" is added to the loop, so the directory is not created if there are
    # no keys
    - "keys"
  loop_control:
    label: "{{ item.0.name }}"

- name: "ensure SSH keys for users are present"
  blockinfile:
    path: "{{ item.0.home_prefix }}/{{ item.0.name }}/.ssh/authorized_keys"
    block: "{{ lookup('file', 'group_vars/all/ssh_keys/' + item.1.id) }}"
    state: "{{ item.1.state }}"
    # When changing value of marker, also update it in task down below
    marker: "# {mark} SSH key for {{ item.1.id }}"
    owner: "{{ item.0.name }}"
    group: "{{ item.0.name }}"
    create: true
  # Only run the above logic when we still want the user to exist.
  when: item.0.state == 'present'
  with_subelements:
    - "{{ users }}"
    - "keys"
  loop_control:
    label:
      user: "{{ item.0.name }}"
      key: "{{ item.1.id }}"

- name: "copy deploy key for private projects on GitHub"
  copy:
    content: "{{ secret_deploy_key }}"
    dest: "/home/ansible/.ssh/deploy_ed25519"
    owner: "ansible"
    group: "ansible"
    mode: "0600"

- name:
    "remove unneeded public part of deploy key for private projects on
    GitHub"
  file:
    path: "/{{ item }}_ed25519.pub"
    state: "absent"
  with_items:
    - "home/ansible/.ssh/deploy"
    - "root/.ssh/id"
    - "home/koala/.ssh/id"

- name: "symlink deploy key for root"
  file:
    src: "/home/ansible/.ssh/{{ deploy_key_name.src }}"
    path: "/root/.ssh/{{ deploy_key_name.dest }}"
    state: link
  vars:
    deploy_key_name:
      src: "deploy_ed25519"
      dest: "id_ed25519"

- name: "remove public keys for root account"
  file:
    path: "/root/.ssh/authorized_keys"
    state: "absent"

# The bootstrap playbook adds the SSH keys (as added by DO), to the ansible
# user. Afterwards, they are re-added and managed by Ansible itself, so the old
# duplicates must be deleted once.
- block:
  - name:
      "save current list of public keys for ansible user"
    shell:
      "sed -n '/# BEGIN SSH key/,$p' ~/.ssh/authorized_keys"
    args:
      # To prevent warning about using a module like lineinfile instead of sed,
      # which is most likely not possible in this case.
      warn: false
    register: "ansible_user_public_keys"
    changed_when: false
    check_mode: false

  - name:
      "remove superfluous public keys for ansible user, added by bootstrap
      playbook"
    copy:
      content: "{{ ansible_user_public_keys.stdout + '\n' }}"
      dest: "~/.ssh/authorized_keys"
  become: false

- name: "copy hardened sshd configuration"
  template:
    src: "templates/{{ path }}.j2"
    dest: "/{{ path }}"
  vars:
    path: "etc/ssh/sshd_config"
  notify: "reboot server"

# Make sure the "reboot server" handler is run now (when notified), and not just
# before Certbot's task, when the handlers are also flushed. Because otherwise
# Certbot would fail, because the kernel's RNG wouldn't be seeded yet.
- meta: "flush_handlers"
